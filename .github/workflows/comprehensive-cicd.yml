# ðŸ§ª EXPERIMENTAL WORKFLOW - FOR TESTING PURPOSES
# This is a custom implementation for learning/experimentation
# For production use, consider these proven alternatives:
# - github/super-linter (code quality)
# - github/codeql-action (security scanning)  
# - GoogleChrome/lighthouse-ci (performance testing)
# - renovatebot/renovate (dependency updates)

name: Comprehensive CI/CD Automation

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]
  schedule:
    # Run daily at 2 AM UTC for dependency updates and security scans
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      debug_enabled:
        description: 'Run the build with tmate debugging enabled'
        required: false
        default: false
      skip_tests:
        description: 'Skip test execution'
        required: false
        default: false

env:
  NODE_VERSION: '18'
  CACHE_VERSION: 'v1'
  MAX_BUILD_TIME: 30

jobs:
  # Job 1: Code Quality and Security Analysis
  code-quality:
    name: Code Quality & Security
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      security_issues: ${{ steps.security_scan.outputs.issues }}
      quality_score: ${{ steps.quality_check.outputs.score }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.npm
        key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}-${{ env.CACHE_VERSION }}
        restore-keys: |
          ${{ runner.os }}-node-
    
    - name: Install dependencies
      run: |
        if [ -f package-lock.json ]; then
          npm ci
        else
          echo "No package-lock.json found, skipping npm install"
        fi
    
    - name: Run ESLint
      id: lint_check
      run: |
        if [ -f .eslintrc.js ] || [ -f .eslintrc.json ]; then
          npx eslint . --format json --output-file eslint-report.json || true
          echo "ESLint completed"
        else
          echo "No ESLint configuration found"
        fi
    
    - name: Security vulnerability scan
      id: security_scan
      run: |
        echo "Running security scan..."
        
        # HTML security checks
        if command -v htmlhint >/dev/null 2>&1; then
          htmlhint --format json . > htmlhint-report.json || true
        else
          echo "HTMLHint not available, installing..."
          npm install -g htmlhint
          htmlhint --format json . > htmlhint-report.json || true
        fi
        
        # Check for common security issues in HTML
        SECURITY_ISSUES=0
        if [ -f htmlhint-report.json ]; then
          SECURITY_ISSUES=$(jq '[.[] | select(.severity == "error")] | length' htmlhint-report.json 2>/dev/null || echo "0")
        fi
        
        echo "issues=$SECURITY_ISSUES" >> $GITHUB_OUTPUT
        echo "Found $SECURITY_ISSUES security issues"
    
    - name: Code quality analysis
      id: quality_check
      run: |
        # Calculate quality score based on various factors
        QUALITY_SCORE=100
        
        # Check for proper HTML structure
        if grep -r "<!DOCTYPE html>" . --include="*.html"; then
          echo "âœ“ DOCTYPE declarations found"
        else
          echo "âœ— Missing DOCTYPE declarations"
          QUALITY_SCORE=$((QUALITY_SCORE - 10))
        fi
        
        # Check for meta tags
        if grep -r "<meta charset=" . --include="*.html"; then
          echo "âœ“ Character encoding meta tags found"
        else
          echo "âœ— Missing character encoding meta tags"
          QUALITY_SCORE=$((QUALITY_SCORE - 5))
        fi
        
        # Check for viewport meta tag
        if grep -r "viewport" . --include="*.html"; then
          echo "âœ“ Viewport meta tags found"
        else
          echo "âœ— Missing viewport meta tags"
          QUALITY_SCORE=$((QUALITY_SCORE - 10))
        fi
        
        echo "score=$QUALITY_SCORE" >> $GITHUB_OUTPUT
        echo "Quality score: $QUALITY_SCORE/100"

  # Job 2: Build and Test
  build-test:
    name: Build & Test
    runs-on: ubuntu-latest
    timeout-minutes: ${{ env.MAX_BUILD_TIME }}
    needs: code-quality
    outputs:
      build_status: ${{ steps.build_step.outputs.status }}
      test_results: ${{ steps.test_step.outputs.results }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Cache build artifacts
      uses: actions/cache@v3
      with:
        path: |
          ~/.npm
          dist/
          build/
        key: ${{ runner.os }}-build-${{ hashFiles('**/package-lock.json', '**/*.js', '**/*.html') }}-${{ env.CACHE_VERSION }}
    
    - name: Install dependencies
      run: |
        if [ -f package-lock.json ]; then
          npm ci
        fi
    
    - name: Build project
      id: build_step
      run: |
        echo "Building project..."
        
        # Create build directory
        mkdir -p dist
        
        # Copy HTML files to dist
        cp *.html dist/ 2>/dev/null || true
        
        # Copy assets if they exist
        if [ -d "assets" ]; then
          cp -r assets dist/
        fi
        
        # Validate HTML files
        for file in dist/*.html; do
          if [ -f "$file" ]; then
            echo "Validating $file..."
            # Basic HTML validation
            if ! grep -q "<!DOCTYPE html>" "$file"; then
              echo "Warning: $file missing DOCTYPE"
            fi
          fi
        done
        
        echo "status=success" >> $GITHUB_OUTPUT
        echo "Build completed successfully"
    
    - name: Run tests
      id: test_step
      if: github.event.inputs.skip_tests != 'true'
      run: |
        echo "Running tests..."
        
        # HTML validation tests
        TEST_RESULTS="{\"passed\": 0, \"failed\": 0, \"total\": 0}"
        PASSED=0
        FAILED=0
        TOTAL=0
        
        for file in *.html; do
          if [ -f "$file" ]; then
            TOTAL=$((TOTAL + 1))
            echo "Testing $file..."
            
            # Test 1: Check for basic HTML structure
            if grep -q "<!DOCTYPE html>" "$file" && grep -q "<html" "$file" && grep -q "</html>" "$file"; then
              echo "âœ“ $file has proper HTML structure"
              PASSED=$((PASSED + 1))
            else
              echo "âœ— $file has incomplete HTML structure"
              FAILED=$((FAILED + 1))
            fi
            
            # Test 2: Check for responsive meta tag
            if grep -q "viewport" "$file"; then
              echo "âœ“ $file has viewport meta tag"
              PASSED=$((PASSED + 1))
            else
              echo "âœ— $file missing viewport meta tag"
              FAILED=$((FAILED + 1))
            fi
          fi
        done
        
        TEST_RESULTS="{\"passed\": $PASSED, \"failed\": $FAILED, \"total\": $TOTAL}"
        echo "results=$TEST_RESULTS" >> $GITHUB_OUTPUT
        echo "Test Results: $PASSED passed, $FAILED failed, $TOTAL total"

  # Job 3: Dependency Updates and Security
  dependency-security:
    name: Dependency Updates & Security
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [code-quality, build-test]
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Check for dependency updates
      id: dep_check
      run: |
        if [ -f package.json ]; then
          npm outdated --json > outdated-report.json 2>/dev/null || echo "{}" > outdated-report.json
          OUTDATED_COUNT=$(jq 'length' outdated-report.json 2>/dev/null || echo "0")
          echo "outdated_count=$OUTDATED_COUNT" >> $GITHUB_OUTPUT
          echo "Found $OUTDATED_COUNT outdated dependencies"
        else
          echo "outdated_count=0" >> $GITHUB_OUTPUT
        fi
    
    - name: Security audit
      run: |
        if [ -f package.json ]; then
          npm audit --audit-level=moderate --json > security-audit.json 2>/dev/null || true
          HIGH_VULNS=$(jq '[.vulnerabilities | to_entries[] | select(.value.severity == "high")] | length' security-audit.json 2>/dev/null || echo "0")
          CRITICAL_VULNS=$(jq '[.vulnerabilities | to_entries[] | select(.value.severity == "critical")] | length' security-audit.json 2>/dev/null || echo "0")
          
          echo "HIGH_VULNERABILITIES=$HIGH_VULNS" >> $GITHUB_ENV
          echo "CRITICAL_VULNERABILITIES=$CRITICAL_VULNS" >> $GITHUB_ENV
          
          if [ "$CRITICAL_VULNS" -gt 0 ]; then
            echo "::warning::Found $CRITICAL_VULNS critical security vulnerabilities"
          fi
          
          if [ "$HIGH_VULNS" -gt 0 ]; then
            echo "::warning::Found $HIGH_VULNS high security vulnerabilities"
          fi
        fi
    
    - name: Create security report
      if: env.CRITICAL_VULNERABILITIES > 0 || env.HIGH_VULNERABILITIES > 0
      run: |
        cat > security-report.md << 'EOF'
        # Security Vulnerability Report
        
        ## Summary
        - **Critical Vulnerabilities**: ${{ env.CRITICAL_VULNERABILITIES }}
        - **High Vulnerabilities**: ${{ env.HIGH_VULNERABILITIES }}
        
        ## Recommendation
        Please review and update dependencies to address security vulnerabilities.
        
        ## Action Required
        - [ ] Review security audit report
        - [ ] Update vulnerable dependencies
        - [ ] Test application after updates
        EOF
        
        echo "Security report generated"

  # Job 4: Performance Optimization
  performance:
    name: Performance Optimization
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: build-test
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Analyze HTML file sizes
      id: file_analysis
      run: |
        echo "Analyzing file sizes..."
        
        # Check HTML file sizes
        LARGE_FILES=0
        TOTAL_SIZE=0
        
        for file in *.html; do
          if [ -f "$file" ]; then
            SIZE=$(stat -c%s "$file")
            TOTAL_SIZE=$((TOTAL_SIZE + SIZE))
            
            # Flag files larger than 100KB
            if [ "$SIZE" -gt 102400 ]; then
              echo "::warning::Large HTML file: $file ($(($SIZE / 1024))KB)"
              LARGE_FILES=$((LARGE_FILES + 1))
            fi
            
            echo "$file: $(($SIZE / 1024))KB"
          fi
        done
        
        echo "large_files=$LARGE_FILES" >> $GITHUB_OUTPUT
        echo "total_size=$TOTAL_SIZE" >> $GITHUB_OUTPUT
        echo "Average file size: $(($TOTAL_SIZE / 1024 / $(ls *.html 2>/dev/null | wc -l)))KB"
    
    - name: Check for optimization opportunities
      run: |
        echo "Checking for optimization opportunities..."
        
        # Check for unoptimized images
        if find . -name "*.jpg" -o -name "*.png" -o -name "*.gif" | grep -q .; then
          echo "Found image files that could be optimized"
        fi
        
        # Check for CSS/JS minification opportunities
        if grep -r "  " . --include="*.html" | grep -q .; then
          echo "Found HTML files with excess whitespace (minification opportunity)"
        fi
        
        echo "Performance analysis completed"

  # Job 5: Deployment (if main branch)
  deploy:
    name: Deploy to GitHub Pages
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [code-quality, build-test, performance]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Pages
      uses: actions/configure-pages@v3
    
    - name: Upload artifact
      uses: actions/upload-pages-artifact@v2
      with:
        path: '.'
    
    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v2

  # Job 6: Notification and Reporting
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [code-quality, build-test, dependency-security, performance, deploy]
    if: always()
    
    steps:
    - name: Generate comprehensive report
      id: report
      run: |
        # Collect all job results
        QUALITY_SCORE="${{ needs.code-quality.outputs.quality_score }}"
        SECURITY_ISSUES="${{ needs.code-quality.outputs.security_issues }}"
        BUILD_STATUS="${{ needs.build-test.outputs.build_status }}"
        TEST_RESULTS="${{ needs.build-test.outputs.test_results }}"
        
        # Create summary
        echo "## Build Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Quality Score**: $QUALITY_SCORE/100" >> $GITHUB_STEP_SUMMARY
        echo "- **Security Issues**: $SECURITY_ISSUES" >> $GITHUB_STEP_SUMMARY
        echo "- **Build Status**: $BUILD_STATUS" >> $GITHUB_STEP_SUMMARY
        echo "- **Test Results**: $TEST_RESULTS" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Status indicators
        if [ "${{ job.status }}" == "success" ]; then
          echo "âœ… All checks passed!" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ job.status }}" == "failure" ]; then
          echo "âŒ Some checks failed. Please review the logs." >> $GITHUB_STEP_SUMMARY
        else
          echo "âš ï¸ Build completed with warnings." >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Check for critical issues
      if: env.CRITICAL_VULNERABILITIES > 0
      run: |
        echo "::error::Critical security vulnerabilities detected. Immediate action required."
        exit 1